import requests
import json
import time
import os
from datetime import datetime
import csv

# ì„œë²„ URL
BASE_URL = "http://localhost:8000"

def save_results_to_files(all_results, summary_stats):
    """ê²°ê³¼ë¥¼ ì—¬ëŸ¬ í˜•íƒœì˜ íŒŒì¼ë¡œ ì €ì¥"""
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # 1. ìƒì„¸ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥
    txt_filename = f"rag_comparison_detailed_{timestamp}.txt"
    with open(txt_filename, "w", encoding="utf-8") as f:
        f.write("=" * 80 + "\n")
        f.write("RAG ì„±ëŠ¥ ë¹„êµ ìƒì„¸ ê²°ê³¼\n")
        f.write(f"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write("=" * 80 + "\n\n")
        
        for i, query_result in enumerate(all_results, 1):
            f.write(f"ì§ˆë¬¸ {i}: {query_result['query']}\n")
            f.write("-" * 60 + "\n")
            f.write(f"ì „ì²´ ì²˜ë¦¬ ì‹œê°„: {query_result['total_time']:.2f}ì´ˆ\n\n")
            
            # ê²°ê³¼ë¥¼ ê´€ë ¨ì„± ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            sorted_results = sorted(query_result['results'], 
                                  key=lambda x: x['relevance_score'], reverse=True)
            
            for j, result in enumerate(sorted_results, 1):
                f.write(f"{j}ìœ„. {result['method']}\n")
                f.write(f"   ì‘ë‹µ ì‹œê°„: {result['response_time']:.2f}ì´ˆ\n")
                f.write(f"   ê´€ë ¨ì„± ì ìˆ˜: {result['relevance_score']:.3f}\n")
                f.write(f"   ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜: {len(result['retrieved_docs'])}\n")
                f.write(f"   ë‹µë³€: {result['response']}\n")
                
                # ê²€ìƒ‰ëœ ë¬¸ì„œë“¤
                f.write(f"   ê²€ìƒ‰ëœ ë¬¸ì„œë“¤:\n")
                for k, doc in enumerate(result['retrieved_docs'], 1):
                    f.write(f"      ë¬¸ì„œ {k}: {doc['content']}\n")
                f.write("\n")
            
            f.write("\n" + "=" * 80 + "\n\n")
        
        # ìš”ì•½ í†µê³„
        f.write("ğŸ“Š ì „ì²´ ìš”ì•½ í†µê³„\n")
        f.write("=" * 80 + "\n")
        for method, stats in summary_stats.items():
            f.write(f"\n{method}:\n")
            f.write(f"   í‰ê·  ì‘ë‹µ ì‹œê°„: {stats['avg_response_time']:.2f}ì´ˆ\n")
            f.write(f"   í‰ê·  ê´€ë ¨ì„± ì ìˆ˜: {stats['avg_relevance_score']:.3f}\n")
            f.write(f"   ìµœê³  ê´€ë ¨ì„± ì ìˆ˜: {stats['max_relevance_score']:.3f}\n")
            f.write(f"   ìµœì € ê´€ë ¨ì„± ì ìˆ˜: {stats['min_relevance_score']:.3f}\n")
    
    # 2. CSV íŒŒì¼ë¡œ ì €ì¥ (ë°ì´í„° ë¶„ì„ìš©)
    csv_filename = f"rag_comparison_data_{timestamp}.csv"
    with open(csv_filename, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        
        # í—¤ë”
        writer.writerow([
            "ì§ˆë¬¸_ë²ˆí˜¸", "ì§ˆë¬¸", "ë°©ë²•", "ì‘ë‹µ_ì‹œê°„(ì´ˆ)", "ê´€ë ¨ì„±_ì ìˆ˜", 
            "ê²€ìƒ‰_ë¬¸ì„œ_ìˆ˜", "ë‹µë³€_ê¸¸ì´", "ìˆœìœ„"
        ])
        
        # ë°ì´í„°
        for i, query_result in enumerate(all_results, 1):
            sorted_results = sorted(query_result['results'], 
                                  key=lambda x: x['relevance_score'], reverse=True)
            
            for j, result in enumerate(sorted_results, 1):
                writer.writerow([
                    i,
                    query_result['query'],
                    result['method'],
                    result['response_time'],
                    result['relevance_score'],
                    len(result['retrieved_docs']),
                    len(result['response']),
                    j
                ])
    
    # 3. ìš”ì•½ í†µê³„ë¥¼ ë³„ë„ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥
    summary_filename = f"rag_summary_{timestamp}.txt"
    with open(summary_filename, "w", encoding="utf-8") as f:
        f.write("RAG ì„±ëŠ¥ ë¹„êµ ìš”ì•½ ë³´ê³ ì„œ\n")
        f.write("=" * 50 + "\n")
        f.write(f"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"ì´ ì§ˆë¬¸ ìˆ˜: {len(all_results)}\n")
        f.write(f"ë¹„êµí•œ ë°©ë²• ìˆ˜: {len(summary_stats)}\n\n")
        
        # ë°©ë²•ë³„ ìˆœìœ„
        method_rankings = {}
        for query_result in all_results:
            sorted_results = sorted(query_result['results'], 
                                  key=lambda x: x['relevance_score'], reverse=True)
            for rank, result in enumerate(sorted_results, 1):
                method = result['method']
                if method not in method_rankings:
                    method_rankings[method] = []
                method_rankings[method].append(rank)
        
        # í‰ê·  ìˆœìœ„ ê³„ì‚°
        f.write("ğŸ“ˆ ë°©ë²•ë³„ í‰ê·  ìˆœìœ„ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ):\n")
        f.write("-" * 30 + "\n")
        avg_rankings = {}
        for method, ranks in method_rankings.items():
            avg_rank = sum(ranks) / len(ranks)
            avg_rankings[method] = avg_rank
            f.write(f"{method}: {avg_rank:.2f}ìœ„\n")
        
        # ìµœê³  ì„±ëŠ¥ ë°©ë²•
        best_method = min(avg_rankings.items(), key=lambda x: x[1])
        f.write(f"\nğŸ† ìµœê³  ì„±ëŠ¥ ë°©ë²•: {best_method[0]} (í‰ê·  {best_method[1]:.2f}ìœ„)\n")
        
        # ìƒì„¸ í†µê³„
        f.write("\nğŸ“Š ìƒì„¸ í†µê³„:\n")
        f.write("-" * 30 + "\n")
        for method, stats in summary_stats.items():
            f.write(f"\n{method}:\n")
            f.write(f"   í‰ê·  ì‘ë‹µ ì‹œê°„: {stats['avg_response_time']:.2f}ì´ˆ\n")
            f.write(f"   í‰ê·  ê´€ë ¨ì„± ì ìˆ˜: {stats['avg_relevance_score']:.3f}\n")
            f.write(f"   ì„±ëŠ¥ ì•ˆì •ì„±: {stats['relevance_std']:.3f} (ë‚®ì„ìˆ˜ë¡ ì•ˆì •)\n")
        
        # ì¶”ì²œì‚¬í•­
        f.write("\nğŸ’¡ ì¶”ì²œì‚¬í•­:\n")
        f.write("-" * 30 + "\n")
        
        fastest_method = min(summary_stats.items(), 
                           key=lambda x: x[1]['avg_response_time'])
        most_relevant = max(summary_stats.items(), 
                          key=lambda x: x[1]['avg_relevance_score'])
        most_stable = min(summary_stats.items(), 
                        key=lambda x: x[1]['relevance_std'])
        
        f.write(f"ê°€ì¥ ë¹ ë¥¸ ë°©ë²•: {fastest_method[0]} ({fastest_method[1]['avg_response_time']:.2f}ì´ˆ)\n")
        f.write(f"ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë°©ë²•: {most_relevant[0]} ({most_relevant[1]['avg_relevance_score']:.3f})\n")
        f.write(f"ê°€ì¥ ì•ˆì •ì ì¸ ë°©ë²•: {most_stable[0]} (í‘œì¤€í¸ì°¨: {most_stable[1]['relevance_std']:.3f})\n")
    
    return txt_filename, csv_filename, summary_filename

def calculate_summary_statistics(all_results):
    """ì „ì²´ ê²°ê³¼ì—ì„œ ìš”ì•½ í†µê³„ ê³„ì‚°"""
    
    method_stats = {}
    
    for query_result in all_results:
        for result in query_result['results']:
            method = result['method']
            
            if method not in method_stats:
                method_stats[method] = {
                    'response_times': [],
                    'relevance_scores': []
                }
            
            method_stats[method]['response_times'].append(result['response_time'])
            method_stats[method]['relevance_scores'].append(result['relevance_score'])
    
    # í†µê³„ ê³„ì‚°
    summary_stats = {}
    for method, data in method_stats.items():
        response_times = data['response_times']
        relevance_scores = data['relevance_scores']
        
        summary_stats[method] = {
            'avg_response_time': sum(response_times) / len(response_times),
            'avg_relevance_score': sum(relevance_scores) / len(relevance_scores),
            'max_relevance_score': max(relevance_scores),
            'min_relevance_score': min(relevance_scores),
            'relevance_std': (sum((x - sum(relevance_scores)/len(relevance_scores))**2 
                                for x in relevance_scores) / len(relevance_scores))**0.5
        }
    
    return summary_stats

def test_rag_comparison():
    print("ğŸ§ª RAG ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    all_results = []  # ëª¨ë“  ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    
    # 1. ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
    print("\n1ï¸âƒ£ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸...")
    try:
        response = requests.get(f"{BASE_URL}/status")
        status = response.json()
        print(f"ë¬¸ì„œ ë¡œë“œë¨: {status['documents_loaded']}")
        print(f"ë¬¸ì„œ ìˆ˜: {status['document_count']}")
    except Exception as e:
        print(f"âŒ ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
        return
    
    # 2. ë¬¸ì„œê°€ ì—†ë‹¤ë©´ í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ì—…ë¡œë“œ
    if not status['documents_loaded']:
        print("\n2ï¸âƒ£ í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ì—…ë¡œë“œ...")
        
        # ë” í’ë¶€í•œ í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ìƒì„±
        test_content = """
        ì¸ê³µì§€ëŠ¥ê³¼ ë¨¸ì‹ ëŸ¬ë‹ ì™„ì „ ê°€ì´ë“œ
        
        1. ì¸ê³µì§€ëŠ¥(AI) ê°œìš”
        ì¸ê³µì§€ëŠ¥(AI)ì€ ì¸ê°„ì˜ ì§€ëŠ¥ì„ ëª¨ë°©í•˜ëŠ” ì»´í“¨í„° ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
        1950ë…„ ì•¨ëŸ° íŠœë§ì´ ì œì•ˆí•œ íŠœë§ í…ŒìŠ¤íŠ¸ë¶€í„° ì‹œì‘ë˜ì–´ í˜„ì¬ê¹Œì§€ ë°œì „í•´ì™”ìŠµë‹ˆë‹¤.
        
        2. ì£¼ìš” AI ê¸°ìˆ ë“¤
        
        2.1 ë¨¸ì‹ ëŸ¬ë‹ (Machine Learning)
        - ì •ì˜: ë°ì´í„°ë¡œë¶€í„° íŒ¨í„´ì„ í•™ìŠµí•˜ì—¬ ì˜ˆì¸¡í•˜ëŠ” ê¸°ìˆ 
        - ì¢…ë¥˜: ì§€ë„í•™ìŠµ, ë¹„ì§€ë„í•™ìŠµ, ê°•í™”í•™ìŠµ
        - í™œìš©: ì¶”ì²œ ì‹œìŠ¤í…œ, ì´ë¯¸ì§€ ë¶„ë¥˜, ìŒì„± ì¸ì‹
        
        2.2 ë”¥ëŸ¬ë‹ (Deep Learning)
        - ì •ì˜: ì¸ê³µì‹ ê²½ë§ì„ ì‚¬ìš©í•œ ë¨¸ì‹ ëŸ¬ë‹ì˜ í•œ ë¶„ì•¼
        - íŠ¹ì§•: ë‹¤ì¸µ ì‹ ê²½ë§, ìë™ íŠ¹ì„± ì¶”ì¶œ
        - í™œìš©: ìì—°ì–´ì²˜ë¦¬, ì»´í“¨í„° ë¹„ì „, ììœ¨ì£¼í–‰
        
        2.3 ìì—°ì–´ì²˜ë¦¬ (NLP)
        - ì •ì˜: ì¸ê°„ì˜ ì–¸ì–´ë¥¼ ì»´í“¨í„°ê°€ ì´í•´í•˜ê³  ì²˜ë¦¬í•˜ëŠ” ê¸°ìˆ 
        - ê¸°ìˆ : í† í°í™”, í’ˆì‚¬ íƒœê¹…, ê°œì²´ëª… ì¸ì‹, ê°ì • ë¶„ì„
        - í™œìš©: ë²ˆì—­, ì±—ë´‡, ë¬¸ì„œ ìš”ì•½, ì§ˆì˜ì‘ë‹µ
        
        2.4 ì»´í“¨í„° ë¹„ì „
        - ì •ì˜: ì´ë¯¸ì§€ì™€ ë¹„ë””ì˜¤ë¥¼ ë¶„ì„í•˜ê³  ì´í•´í•˜ëŠ” ê¸°ìˆ 
        - ê¸°ìˆ : ê°ì²´ ê²€ì¶œ, ì´ë¯¸ì§€ ë¶„í• , ì–¼êµ´ ì¸ì‹
        - í™œìš©: ì˜ë£Œ ì§„ë‹¨, ììœ¨ì£¼í–‰, ë³´ì•ˆ ì‹œìŠ¤í…œ
        
        3. RAG (Retrieval-Augmented Generation)
        
        3.1 RAGë€?
        RAGëŠ” ê²€ìƒ‰ ì¦ê°• ìƒì„± ê¸°ìˆ ë¡œ, ì™¸ë¶€ ì§€ì‹ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•œ í›„ 
        ê·¸ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” AI ê¸°ìˆ ì…ë‹ˆë‹¤.
        
        3.2 RAGì˜ êµ¬ì„±ìš”ì†Œ
        - ë¬¸ì„œ ì„ë² ë”©: í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
        - ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤: ì„ë² ë”©ëœ ë¬¸ì„œ ì €ì¥
        - ê²€ìƒ‰ê¸°: ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œ ê²€ìƒ‰
        - ìƒì„±ê¸°: ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ ìƒì„±
        
        3.3 RAGì˜ ì¥ì 
        - ìµœì‹  ì •ë³´ ë°˜ì˜ ê°€ëŠ¥
        - í™˜ê°(Hallucination) í˜„ìƒ ê°ì†Œ
        - íˆ¬ëª…í•œ ì •ë³´ ì¶œì²˜ ì œê³µ
        - ë„ë©”ì¸ íŠ¹í™” ì§€ì‹ í™œìš©
        
        3.4 RAG ìµœì í™” ë°©ë²•
        - Basic RAG: ê¸°ë³¸ì ì¸ ë²¡í„° ê²€ìƒ‰
        - Multi-Query RAG: ë‹¤ì¤‘ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰ ë‹¤ì–‘ì„± í™•ë³´
        - Ensemble Retrieval: ë²¡í„° ê²€ìƒ‰ê³¼ í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°í•©
        - Contextual Compression: ê´€ë ¨ ì •ë³´ë§Œ ì„ ë³„
        - Hierarchical Chunking: ê³„ì¸µì  ë¬¸ì„œ ë¶„í• 
        - Semantic Chunking: ì˜ë¯¸ ê¸°ë°˜ ë¬¸ì„œ ë¶„í• 
        
        4. ë¨¸ì‹ ëŸ¬ë‹ vs ë”¥ëŸ¬ë‹ ë¹„êµ
        
        4.1 ê³µí†µì 
        - ë‘˜ ë‹¤ ë°ì´í„°ë¡œë¶€í„° í•™ìŠµ
        - ì˜ˆì¸¡ê³¼ ë¶„ë¥˜ ì‘ì—… ìˆ˜í–‰
        - í†µê³„ì  ëª¨ë¸ë§ ê¸°ë°˜
        
        4.2 ì°¨ì´ì 
        ë¨¸ì‹ ëŸ¬ë‹:
        - ìƒëŒ€ì ìœ¼ë¡œ ë‹¨ìˆœí•œ ì•Œê³ ë¦¬ì¦˜
        - íŠ¹ì„± ê³µí•™ì´ ì¤‘ìš”
        - ì†ŒëŸ‰ ë°ì´í„°ë¡œë„ í•™ìŠµ ê°€ëŠ¥
        - í•´ì„ì´ ìš©ì´
        
        ë”¥ëŸ¬ë‹:
        - ë³µì¡í•œ ì‹ ê²½ë§ êµ¬ì¡°
        - ìë™ íŠ¹ì„± ì¶”ì¶œ
        - ëŒ€ìš©ëŸ‰ ë°ì´í„° í•„ìš”
        - ë†’ì€ ì„±ëŠ¥, ë‚®ì€ í•´ì„ì„±
        
        5. AIì˜ ë¯¸ë˜ ì „ë§
        - ììœ¨ì£¼í–‰ì°¨ì˜ ìƒìš©í™”
        - ì˜ë£Œ AIì˜ í™•ì‚°
        - ì°½ì‘ AIì˜ ë°œì „
        - ë²”ìš© ì¸ê³µì§€ëŠ¥(AGI) ì—°êµ¬
        """
        
        with open("comprehensive_ai_guide.txt", "w", encoding="utf-8") as f:
            f.write(test_content)
        
        # íŒŒì¼ ì—…ë¡œë“œ
        with open("comprehensive_ai_guide.txt", "rb") as f:
            files = {"file": ("comprehensive_ai_guide.txt", f, "text/plain")}
            response = requests.post(f"{BASE_URL}/upload", files=files)
            if response.status_code == 200:
                result = response.json()
                print(f"âœ… ì—…ë¡œë“œ ì„±ê³µ: {result['filename']}, ì²­í¬ ìˆ˜: {result['document_count']}")
            else:
                print(f"âŒ ì—…ë¡œë“œ ì‹¤íŒ¨: {response.text}")
                return
    
    # 3. RAG ë°©ë²•ë“¤ ë¹„êµ
    print("\n3ï¸âƒ£ RAG ë°©ë²•ë“¤ ì„±ëŠ¥ ë¹„êµ...")
    
    test_queries = [
        "ì¸ê³µì§€ëŠ¥ì˜ ì£¼ìš” ê¸°ìˆ ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "RAGì˜ ì¥ì ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        "ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "ìì—°ì–´ì²˜ë¦¬ì˜ ì£¼ìš” ê¸°ìˆ ë“¤ì„ ë‚˜ì—´í•´ì£¼ì„¸ìš”.",
        "RAG ìµœì í™” ë°©ë²•ë“¤ì—ëŠ” ì–´ë–¤ ê²ƒë“¤ì´ ìˆë‚˜ìš”?"
    ]
    
    methods = ["basic_rag", "multi_query", "ensemble_retrieval", "hierarchical_chunking"]
    
    for i, query in enumerate(test_queries, 1):
        print(f"\nğŸ“ ì§ˆë¬¸ {i}: {query}")
        
        # ë¹„êµ ìš”ì²­
        comparison_data = {
            "query": query,
            "optimization_methods": methods,
            "chunk_size": 1000,
            "chunk_overlap": 200,
            "top_k": 3
        }
        
        start_time = time.time()
        try:
            response = requests.post(f"{BASE_URL}/compare", json=comparison_data)
            total_time = time.time() - start_time
            
            if response.status_code == 200:
                results = response.json()["results"]
                
                # ê²°ê³¼ ì €ì¥
                query_result = {
                    "query": query,
                    "results": results,
                    "total_time": total_time
                }
                all_results.append(query_result)
                
                print(f"â±ï¸ ì „ì²´ ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ")
                print("\nğŸ“Š ê²°ê³¼ ë¹„êµ:")
                
                # ê²°ê³¼ ì •ë ¬ (ê´€ë ¨ì„± ì ìˆ˜ ê¸°ì¤€)
                sorted_results = sorted(results, key=lambda x: x['relevance_score'], reverse=True)
                
                for j, result in enumerate(sorted_results, 1):
                    print(f"\n{j}ìœ„. {result['method']}")
                    print(f"   â±ï¸ ì‘ë‹µì‹œê°„: {result['response_time']:.2f}ì´ˆ")
                    print(f"   ğŸ“ˆ ê´€ë ¨ì„± ì ìˆ˜: {result['relevance_score']:.3f}")
                    print(f"   ğŸ“„ ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜: {len(result['retrieved_docs'])}")
                    print(f"   ğŸ’¬ ë‹µë³€: {result['response'][:150]}...")
                    
            else:
                print(f"âŒ ë¹„êµ ì‹¤íŒ¨: {response.text}")
                
        except Exception as e:
            print(f"âŒ ìš”ì²­ ì˜¤ë¥˜: {e}")
    
    # 4. ê²°ê³¼ ë¶„ì„ ë° ì €ì¥
    if all_results:
        print("\n4ï¸âƒ£ ê²°ê³¼ ë¶„ì„ ë° íŒŒì¼ ì €ì¥...")
        
        # ìš”ì•½ í†µê³„ ê³„ì‚°
        summary_stats = calculate_summary_statistics(all_results)
        
        # íŒŒì¼ ì €ì¥
        txt_file, csv_file, summary_file = save_results_to_files(all_results, summary_stats)
        
        print("\nğŸ“ ì €ì¥ëœ íŒŒì¼ë“¤:")
        print(f"   ğŸ“„ ìƒì„¸ ê²°ê³¼: {txt_file}")
        print(f"   ğŸ“Š ë°ì´í„° CSV: {csv_file}")
        print(f"   ğŸ“‹ ìš”ì•½ ë³´ê³ ì„œ: {summary_file}")
        
        # ê°„ë‹¨í•œ ìµœì¢… ìš”ì•½ ì¶œë ¥
        print("\nğŸ† ìµœì¢… ìš”ì•½:")
        print("-" * 40)
        
        # í‰ê·  ìˆœìœ„ ê³„ì‚°
        method_rankings = {}
        for query_result in all_results:
            sorted_results = sorted(query_result['results'], 
                                  key=lambda x: x['relevance_score'], reverse=True)
            for rank, result in enumerate(sorted_results, 1):
                method = result['method']
                if method not in method_rankings:
                    method_rankings[method] = []
                method_rankings[method].append(rank)
        
        for method, ranks in method_rankings.items():
            avg_rank = sum(ranks) / len(ranks)
            avg_time = summary_stats[method]['avg_response_time']
            avg_relevance = summary_stats[method]['avg_relevance_score']
            print(f"{method}:")
            print(f"   í‰ê·  ìˆœìœ„: {avg_rank:.1f}ìœ„")
            print(f"   í‰ê·  ì‘ë‹µì‹œê°„: {avg_time:.2f}ì´ˆ")
            print(f"   í‰ê·  ê´€ë ¨ì„±: {avg_relevance:.3f}")
            print()
    
    print("\nğŸ‰ RAG ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("ìƒì„±ëœ íŒŒì¼ë“¤ì„ í™•ì¸í•˜ì—¬ ìƒì„¸í•œ ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

if __name__ == "__main__":
    test_rag_comparison()